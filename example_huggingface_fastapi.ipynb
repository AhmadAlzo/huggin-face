{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6692c736",
   "metadata": {},
   "source": [
    "# main.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a43bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from operator import mod\n",
    "# from pickle import TRUE\n",
    "# from typing import Union\n",
    "# from fastapi import Depends, FastAPI\n",
    "# from numpy import true_divide\n",
    "# from pydantic import BaseModel\n",
    "# from model import Model, get_custom_task_and_model, get_summarization_and_model\n",
    "\n",
    "# app = FastAPI()\n",
    "\n",
    "\n",
    "# @app.get('/')\n",
    "# async def root():\n",
    "#     return {'message': 'Hello World'}\n",
    "\n",
    "\n",
    "# @app.get('/v1/ml/{ml_model}')\n",
    "# async def executeScript(ml_model):\n",
    "#     return {'ML Execution': ml_model}\n",
    "\n",
    "\n",
    "# @app.get('/items/')\n",
    "# async def read_item(skip: int = 0, limit: int = 10):\n",
    "#     return fake_items_db[skip: skip + limit]\n",
    "\n",
    "\n",
    "# class Item(BaseModel):\n",
    "#     name: str\n",
    "#     description: Union[str, None] = None\n",
    "#     price: float\n",
    "#     tax: Union[float, None] = None\n",
    "\n",
    "# class Request(BaseModel):\n",
    "#     request_text: str\n",
    "\n",
    "# task_list = ['test-classification','ner','question-answering','translation_en_to_de','summarization']\n",
    "# model_list = ['facebook/bart-large-cnn','roberta-large-mnli','distilbert-base-uncased-finetuned-sst-2-english','TFBartForConditionalGeneration', 'TFBlenderbotForConditionalGeneration', 'TFBlenderbotSmallForConditionalGeneration', 'TFEncoderDecoderModel', 'TFLEDForConditionalGeneration', 'TFMarianMTModel', 'TFMBartForConditionalGeneration', 'TFMT5ForConditionalGeneration', 'TFPegasusForConditionalGeneration', 'TFT5ForConditionalGeneration','t5-small','google/pegasus-xsum']\n",
    "\n",
    "# @app.post('/model/{custom_model}/task/{task}')\n",
    "# async def makePrediction(request: Request, custom_model, task):\n",
    "#     if(len(task)==0):\n",
    "#         task = 'text-classification'\n",
    "#     if(len(custom_model)==0):\n",
    "#         print('Using default Model')\n",
    "#         custom_model = ''\n",
    "#     task = validateTask(task)\n",
    "#     custom_model = validateModel(custom_model)\n",
    "#     print('Applying Task: ' + task)\n",
    "#     print('Applying Model: ' + custom_model)\n",
    "#     if task == 'summarization':\n",
    "#         model: Model = get_summarization_and_model(custom_model)\n",
    "#         return model.summarize(request.request_text)\n",
    "#     else:\n",
    "#         model: Model = get_custom_task_and_model(task,custom_model)\n",
    "#         return model.predict(request.request_text)\n",
    "\n",
    "# def validateTask(task):\n",
    "#     if task in task_list:\n",
    "#         return task\n",
    "#     else:\n",
    "#         print('Task: ' + task + ' is not available, taking default task')\n",
    "#         return 'text-classification'\n",
    "\n",
    "# def validateModel(model):\n",
    "#     model = model.replace(':::','/')\n",
    "#     if model in model_list:\n",
    "#         return model\n",
    "#     else:\n",
    "#         print('Model: ' + model + ' is not available, taking default model')\n",
    "#         return 'distilbert-base-uncased-finetuned-sst-2-english'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16116f6f",
   "metadata": {},
   "source": [
    "# model.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8630ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from urllib.request import urlopen\n",
    "# import pandas as pd\n",
    "# from transformers import pipeline\n",
    "# import platform\n",
    "# print(platform.python_version())\n",
    "\n",
    "# #from pip import _internal\n",
    "# #import tensorflow as tf\n",
    "# #tf.test.gpu_device_name()\n",
    "# #from transformers import pipeline\n",
    "\n",
    "# #task_bearer = pipeline(\"text-classification\")\n",
    "# #summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# class Model:\n",
    "        \n",
    "#     def __init__(self, task, model):\n",
    "#         if(len(model)==0):\n",
    "#             self.task_bearer = pipeline(task)\n",
    "#         if(task == 'summarization'):\n",
    "#             self.summarizer = pipeline(task,model=model)\n",
    "#         else:\n",
    "#             self.task_bearer = pipeline(task,model=model)\n",
    "\n",
    "#     def predict(self, text):\n",
    "#         outputs = self.task_bearer(text)\n",
    "#         return pd.DataFrame(outputs)\n",
    "    \n",
    "#     def summarize(self, text):\n",
    "#         outputs = self.summarizer(text, max_length=50, clean_up_tokenization_spaces=True, truncating=True)\n",
    "#         return pd.DataFrame(outputs)\n",
    "\n",
    "# def get_default_task():\n",
    "#     return Model(\"text-classification\",\"\")\n",
    "\n",
    "# def get_custom_task(custom_task):\n",
    "#     return Model(custom_task)\n",
    "\n",
    "# def get_custom_task_and_model(custom_task,model):\n",
    "#     return Model(custom_task,model)\n",
    "\n",
    "# def get_summarization_and_model(model):\n",
    "#     return Model('summarization',model)\n",
    "\n",
    "\n",
    "# #classifier = pipeline(\"text-classification\")\n",
    "\n",
    "# # outputs = classifier(text)\n",
    "# # print(pd.DataFrame(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea748208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
